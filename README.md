# Projeto PrÃ¡tico â€” Web Mining & Crawler Scraping

## Pipeline de Web Scraping para Banco AnalÃ­tico Financeiro

---

### ğŸ“˜ Tema
MovimentaÃ§Ãµes da **Berkshire Hathaway** e o impacto das decisÃµes de **Warren Buffett** no mercado financeiro.

O projeto desenvolve um pipeline de **coleta, transformaÃ§Ã£o e carga (ETL)** para anÃ¡lise das movimentaÃ§Ãµes de portfÃ³lio da Berkshire Hathaway, observando como essas decisÃµes influenciam o comportamento do mercado. Warren Buffett Ã© reconhecido mundialmente por suas decisÃµes de investimento, tornando o estudo dessas movimentaÃ§Ãµes altamente relevante para anÃ¡lise financeira.

---

## ğŸ§  Objetivo Geral

Construir um **pipeline ETL completo** que:

- Coleta dados de **trÃªs fontes distintas** (duas via scraping e uma via API);
- Realiza o tratamento e padronizaÃ§Ã£o dos dados obtidos;
- Gera arquivos estruturados no formato **Parquet**, simulando um **banco analÃ­tico local**;
- Permite exploraÃ§Ã£o futura em **SQL** e **dashboards analÃ­ticos**.

---

## âš™ï¸ Ferramentas e Tecnologias Utilizadas

- **Linguagem:** Python 3.9+
- **Ambiente de desenvolvimento:** VSCode com Jupyter Notebook (`.ipynb`)
- **Bibliotecas principais:**
  - `requests` e `BeautifulSoup` â€” Web Scraping
  - `selenium` â€” scraping dinÃ¢mico (quando necessÃ¡rio)
  - `pandas` e `pyarrow` â€” manipulaÃ§Ã£o e exportaÃ§Ã£o de dados
  - `datetime` e `os` â€” controle de execuÃ§Ã£o e organizaÃ§Ã£o de arquivos
- **Formato de saÃ­da dos dados:** `.parquet`

---

## ğŸ§© Estrutura Geral do Pipeline ETL

1. **Coleta de Dados**
   - **1.1 SÃ©ries histÃ³ricas via API** (*Alpha Vantage*);
   - **1.2 MovimentaÃ§Ãµes da Berkshire Hathaway** (Web Scraping);
   - **1.3 NotÃ­cias sobre Warren Buffett e empresas relacionadas** (Web Scraping).

2. **TransformaÃ§Ã£o de Dados**
   - Limpeza, padronizaÃ§Ã£o, deduplicaÃ§Ã£o e ajustes de tipos.

3. **Carga de Dados**
   - ExportaÃ§Ã£o dos resultados tratados para arquivos `.parquet`.

---

## ğŸ“ Como Executar

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/seu-usuario/seu-repositorio.git
```

2. Configure sua API Key (Alpha Vantage) no arquivo .env:
   ALPHA_VANTAGE_API_KEY=your_api_key_here

3. Execute os notebooks

## ğŸ“‚ Estrutura de Pastas
```bash
/project-root
â”‚
â”œâ”€â”€ data/           # Arquivos brutos e processados (.parquet)
â”œâ”€â”€ notebooks/      # Jupyter notebooks de anÃ¡lise e testes
â”œâ”€â”€ src/            # Scripts e mÃ³dulos Python
â”œâ”€â”€ logs/           # Logs de execuÃ§Ã£o (ignorado pelo git)
â”œâ”€â”€ .gitignore      # Arquivos/pastas a serem ignorados
â””â”€â”€ README.md
```

##âš ï¸ ObservaÃ§Ãµes Importantes
- *Chaves API* nunca devem ser commitadas. Use ```.env``` para manter seguras.
- *Logs e arquivos temporÃ¡rios* estÃ£o incluÃ­dos no ```.gitignore```.
- Este projeto Ã© um exercÃ­cio prÃ¡tico de Web Mining e ETL, ideal para aprendizado e anÃ¡lise exploratÃ³ria.

##ğŸ’¡ PossÃ­veis ExtensÃµes Futuras
- IntegraÃ§Ã£o com dashboards em *Power BI* ou *Tableau*.
- AutomatizaÃ§Ã£o completa com *Airflow* ou *Prefect*.
- AdiÃ§Ã£o de mais fontes de notÃ­cias financeiras e anÃ¡lise de sentimento.
